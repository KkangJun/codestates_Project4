{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from category_encoders import OrdinalEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GRU, Dropout, Input, BatchNormalization, Activation\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "  host='192.168.35.23',\n",
    "  dbname='train_db',\n",
    "  user='project4',\n",
    "  password='abcdqwer',\n",
    "  port='5432'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5y/8vxkxcq10jbbp_61mxm4tcqw0000gn/T/ipykernel_37287/557139081.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  dataset = pd.read_sql(\"SELECT * FROM train_cong\", conn)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_sql(\"SELECT * FROM train_cong\", conn)\n",
    "dataset_cp = dataset.copy()\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>number_asc</th>\n",
       "      <th>week</th>\n",
       "      <th>line</th>\n",
       "      <th>st_code</th>\n",
       "      <th>st_name</th>\n",
       "      <th>clss</th>\n",
       "      <th>time</th>\n",
       "      <th>congestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>평일</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>서울역</td>\n",
       "      <td>상선</td>\n",
       "      <td>1000</td>\n",
       "      <td>26.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>평일</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>서울역</td>\n",
       "      <td>상선</td>\n",
       "      <td>1030</td>\n",
       "      <td>23.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>평일</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>서울역</td>\n",
       "      <td>상선</td>\n",
       "      <td>1100</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>평일</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>서울역</td>\n",
       "      <td>상선</td>\n",
       "      <td>1130</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>평일</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>서울역</td>\n",
       "      <td>상선</td>\n",
       "      <td>1200</td>\n",
       "      <td>21.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63043</th>\n",
       "      <td>63044</td>\n",
       "      <td>1</td>\n",
       "      <td>일요일</td>\n",
       "      <td>8</td>\n",
       "      <td>2827</td>\n",
       "      <td>모란</td>\n",
       "      <td>하선</td>\n",
       "      <td>730</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63044</th>\n",
       "      <td>63045</td>\n",
       "      <td>1</td>\n",
       "      <td>일요일</td>\n",
       "      <td>8</td>\n",
       "      <td>2827</td>\n",
       "      <td>모란</td>\n",
       "      <td>하선</td>\n",
       "      <td>800</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63045</th>\n",
       "      <td>63046</td>\n",
       "      <td>1</td>\n",
       "      <td>일요일</td>\n",
       "      <td>8</td>\n",
       "      <td>2827</td>\n",
       "      <td>모란</td>\n",
       "      <td>하선</td>\n",
       "      <td>830</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63046</th>\n",
       "      <td>63047</td>\n",
       "      <td>1</td>\n",
       "      <td>일요일</td>\n",
       "      <td>8</td>\n",
       "      <td>2827</td>\n",
       "      <td>모란</td>\n",
       "      <td>하선</td>\n",
       "      <td>900</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63047</th>\n",
       "      <td>63048</td>\n",
       "      <td>1</td>\n",
       "      <td>일요일</td>\n",
       "      <td>8</td>\n",
       "      <td>2827</td>\n",
       "      <td>모란</td>\n",
       "      <td>하선</td>\n",
       "      <td>930</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63048 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  number_asc week  line  st_code st_name clss  time  congestion\n",
       "0          1           1   평일     1      150     서울역   상선  1000        26.6\n",
       "1          2           1   평일     1      150     서울역   상선  1030        23.4\n",
       "2          3           1   평일     1      150     서울역   상선  1100        22.4\n",
       "3          4           1   평일     1      150     서울역   상선  1130        22.1\n",
       "4          5           1   평일     1      150     서울역   상선  1200        21.5\n",
       "...      ...         ...  ...   ...      ...     ...  ...   ...         ...\n",
       "63043  63044           1  일요일     8     2827      모란   하선   730         0.0\n",
       "63044  63045           1  일요일     8     2827      모란   하선   800         0.0\n",
       "63045  63046           1  일요일     8     2827      모란   하선   830         0.0\n",
       "63046  63047           1  일요일     8     2827      모란   하선   900         0.0\n",
       "63047  63048           1  일요일     8     2827      모란   하선   930         0.0\n",
       "\n",
       "[63048 rows x 9 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(['id', 'number_asc', 'st_name'], axis=1, inplace=True, errors='ignore')\n",
    "dataset.sort_values(['week', 'st_code', 'clss', 'time'], inplace=True)\n",
    "dataset.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_cp[dataset_cp['line'] == 15][['st_code', 'st_name','clss', 'week']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이동 방향에 따른 역번호 증가\n",
    "# 1호선(상선 증가) , 2호선(내선 증가), 3호선(하선 증가), 4호선(상선 증가), 5호선(하선 증가), 6호선(하선 증가), 7호선(하선 증가), 8(하선 증가)\n",
    "# line 13(2호선), line 14(2호선), line 15(5호선)\n",
    "\n",
    "dataset = dataset.replace({'평일':1, '토요일':2, '일요일':3, '상선':1, '하선':2, '내선':3, '외선':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = dataset.drop('congestion', axis=1)\n",
    "y_train = dataset['congestion']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(model_path + '/scaler_pickle.pkl', 'wb') as pklf:\n",
    "  pickle.dump(scaler, pklf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>line</th>\n",
       "      <th>st_code</th>\n",
       "      <th>clss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63043</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2827</td>\n",
       "      <td>2</td>\n",
       "      <td>2130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63044</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2827</td>\n",
       "      <td>2</td>\n",
       "      <td>2200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63045</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2827</td>\n",
       "      <td>2</td>\n",
       "      <td>2230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63046</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2827</td>\n",
       "      <td>2</td>\n",
       "      <td>2300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63047</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2827</td>\n",
       "      <td>2</td>\n",
       "      <td>2330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63048 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       week  line  st_code  clss  time\n",
       "0         3     1      150     1   530\n",
       "1         3     1      150     1   600\n",
       "2         3     1      150     1   630\n",
       "3         3     1      150     1   700\n",
       "4         3     1      150     1   730\n",
       "...     ...   ...      ...   ...   ...\n",
       "63043     1     8     2827     2  2130\n",
       "63044     1     8     2827     2  2200\n",
       "63045     1     8     2827     2  2230\n",
       "63046     1     8     2827     2  2300\n",
       "63047     1     8     2827     2  2330\n",
       "\n",
       "[63048 rows x 5 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((63048, 5), (63048,))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model():\n",
    "  inputs = Input(shape=(x_train.shape[1]))\n",
    "  \n",
    "  layer = Dense(512, kernel_initializer='he_normal')(inputs)\n",
    "  layer = BatchNormalization()(layer)\n",
    "  layer = Activation('relu')(layer)\n",
    "  # layer = Dropout(0.2)(layer)\n",
    "  \n",
    "  layer = Dense(256, kernel_initializer='he_normal')(layer)\n",
    "  layer = BatchNormalization()(layer)\n",
    "  layer = Activation('relu')(layer)\n",
    "  # layer = Dropout(0.2)(layer)\n",
    "  \n",
    "  layer = Dense(128, kernel_initializer='he_normal')(layer)\n",
    "  layer = BatchNormalization()(layer)\n",
    "  layer = Activation('relu')(layer)\n",
    "  # layer = Dropout(0.2)(layer)\n",
    "  \n",
    "  layer = Dense(64, kernel_initializer='he_normal')(layer)\n",
    "  layer = BatchNormalization()(layer)\n",
    "  layer = Activation('relu')(layer)\n",
    "  # layer = Dropout(0.2)(layer)\n",
    "  \n",
    "  outputs = Dense(1, name='output')(layer)\n",
    "  \n",
    "  model = Model(inputs=inputs, outputs=outputs)\n",
    "  model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 14:06:34.964980: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493/493 [==============================] - ETA: 0s - loss: 321.9554\n",
      "Epoch 1: loss improved from inf to 321.95541, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 7s 13ms/step - loss: 321.9554\n",
      "Epoch 2/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 157.0758\n",
      "Epoch 2: loss improved from 321.95541 to 157.07582, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 157.0758\n",
      "Epoch 3/300\n",
      "492/493 [============================>.] - ETA: 0s - loss: 151.9651\n",
      "Epoch 3: loss improved from 157.07582 to 151.99036, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 151.9904\n",
      "Epoch 4/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 147.8235\n",
      "Epoch 4: loss improved from 151.99036 to 147.82765, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 147.8277\n",
      "Epoch 5/300\n",
      "492/493 [============================>.] - ETA: 0s - loss: 145.5866\n",
      "Epoch 5: loss improved from 147.82765 to 145.65816, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 145.6582\n",
      "Epoch 6/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 145.5412\n",
      "Epoch 6: loss improved from 145.65816 to 145.54120, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 145.5412\n",
      "Epoch 7/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 143.9718\n",
      "Epoch 7: loss improved from 145.54120 to 143.88829, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 143.8883\n",
      "Epoch 8/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 143.9327\n",
      "Epoch 8: loss did not improve from 143.88829\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 143.9089\n",
      "Epoch 9/300\n",
      "492/493 [============================>.] - ETA: 0s - loss: 142.3196\n",
      "Epoch 9: loss improved from 143.88829 to 142.37207, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 142.3721\n",
      "Epoch 10/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 142.2839\n",
      "Epoch 10: loss improved from 142.37207 to 142.28394, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 142.2839\n",
      "Epoch 11/300\n",
      "489/493 [============================>.] - ETA: 0s - loss: 141.5716\n",
      "Epoch 11: loss improved from 142.28394 to 141.71199, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 141.7120\n",
      "Epoch 12/300\n",
      "489/493 [============================>.] - ETA: 0s - loss: 141.9819\n",
      "Epoch 12: loss did not improve from 141.71199\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 141.8801\n",
      "Epoch 13/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 141.2503\n",
      "Epoch 13: loss improved from 141.71199 to 141.25034, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 141.2503\n",
      "Epoch 14/300\n",
      "492/493 [============================>.] - ETA: 0s - loss: 140.5620\n",
      "Epoch 14: loss improved from 141.25034 to 140.57712, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 140.5771\n",
      "Epoch 15/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 140.4279\n",
      "Epoch 15: loss improved from 140.57712 to 140.34669, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 140.3467\n",
      "Epoch 16/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 141.3936\n",
      "Epoch 16: loss did not improve from 140.34669\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 141.3343\n",
      "Epoch 17/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 140.7865\n",
      "Epoch 17: loss did not improve from 140.34669\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 140.6540\n",
      "Epoch 18/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 140.1136\n",
      "Epoch 18: loss improved from 140.34669 to 140.02345, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 140.0235\n",
      "Epoch 19/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 140.2088\n",
      "Epoch 19: loss did not improve from 140.02345\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 140.2088\n",
      "Epoch 20/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 140.5732\n",
      "Epoch 20: loss did not improve from 140.02345\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 140.6633\n",
      "Epoch 21/300\n",
      "489/493 [============================>.] - ETA: 0s - loss: 140.2295\n",
      "Epoch 21: loss did not improve from 140.02345\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 140.2189\n",
      "Epoch 22/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 139.5631\n",
      "Epoch 22: loss improved from 140.02345 to 139.56311, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 139.5631\n",
      "Epoch 23/300\n",
      "489/493 [============================>.] - ETA: 0s - loss: 139.2595\n",
      "Epoch 23: loss improved from 139.56311 to 139.04904, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 139.0490\n",
      "Epoch 24/300\n",
      "489/493 [============================>.] - ETA: 0s - loss: 139.8771\n",
      "Epoch 24: loss did not improve from 139.04904\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 139.6726\n",
      "Epoch 25/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 138.4928\n",
      "Epoch 25: loss improved from 139.04904 to 138.49281, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 138.4928\n",
      "Epoch 26/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 138.6759\n",
      "Epoch 26: loss did not improve from 138.49281\n",
      "493/493 [==============================] - 7s 14ms/step - loss: 138.6759\n",
      "Epoch 27/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 138.3204\n",
      "Epoch 27: loss improved from 138.49281 to 138.32036, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 7s 14ms/step - loss: 138.3204\n",
      "Epoch 28/300\n",
      "489/493 [============================>.] - ETA: 0s - loss: 138.3731\n",
      "Epoch 28: loss improved from 138.32036 to 138.29199, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 138.2920\n",
      "Epoch 29/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 139.0933\n",
      "Epoch 29: loss did not improve from 138.29199\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 139.0933\n",
      "Epoch 30/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 137.9344\n",
      "Epoch 30: loss improved from 138.29199 to 138.07274, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 138.0727\n",
      "Epoch 31/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 136.8014\n",
      "Epoch 31: loss improved from 138.07274 to 136.80142, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 136.8014\n",
      "Epoch 32/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 137.3473\n",
      "Epoch 32: loss did not improve from 136.80142\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 137.5156\n",
      "Epoch 33/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 137.0996\n",
      "Epoch 33: loss did not improve from 136.80142\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 137.1190\n",
      "Epoch 34/300\n",
      "492/493 [============================>.] - ETA: 0s - loss: 137.7781\n",
      "Epoch 34: loss did not improve from 136.80142\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 137.7502\n",
      "Epoch 35/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 136.4935\n",
      "Epoch 35: loss improved from 136.80142 to 136.52142, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 136.5214\n",
      "Epoch 36/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 135.5630\n",
      "Epoch 36: loss improved from 136.52142 to 135.87926, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 135.8793\n",
      "Epoch 37/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 135.0451\n",
      "Epoch 37: loss improved from 135.87926 to 135.06059, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 135.0606\n",
      "Epoch 38/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 135.1324\n",
      "Epoch 38: loss did not improve from 135.06059\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 135.0919\n",
      "Epoch 39/300\n",
      "489/493 [============================>.] - ETA: 0s - loss: 133.4426\n",
      "Epoch 39: loss improved from 135.06059 to 133.37903, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 133.3790\n",
      "Epoch 40/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 131.5254\n",
      "Epoch 40: loss improved from 133.37903 to 131.43300, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 131.4330\n",
      "Epoch 41/300\n",
      "492/493 [============================>.] - ETA: 0s - loss: 127.3305\n",
      "Epoch 41: loss improved from 131.43300 to 127.28685, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 127.2868\n",
      "Epoch 42/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 121.8458\n",
      "Epoch 42: loss improved from 127.28685 to 122.09131, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 122.0913\n",
      "Epoch 43/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 117.7806\n",
      "Epoch 43: loss improved from 122.09131 to 117.75014, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 117.7501\n",
      "Epoch 44/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 114.7261\n",
      "Epoch 44: loss improved from 117.75014 to 114.72610, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 114.7261\n",
      "Epoch 45/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 112.2546\n",
      "Epoch 45: loss improved from 114.72610 to 112.37116, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 112.3712\n",
      "Epoch 46/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 110.6471\n",
      "Epoch 46: loss improved from 112.37116 to 110.55669, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 110.5567\n",
      "Epoch 47/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 109.6810\n",
      "Epoch 47: loss improved from 110.55669 to 109.61891, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 109.6189\n",
      "Epoch 48/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 106.5726\n",
      "Epoch 48: loss improved from 109.61891 to 106.57260, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 106.5726\n",
      "Epoch 49/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 105.7933\n",
      "Epoch 49: loss improved from 106.57260 to 105.99653, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 7s 13ms/step - loss: 105.9965\n",
      "Epoch 50/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 104.6533\n",
      "Epoch 50: loss improved from 105.99653 to 104.54169, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 7s 14ms/step - loss: 104.5417\n",
      "Epoch 51/300\n",
      "492/493 [============================>.] - ETA: 0s - loss: 103.2840\n",
      "Epoch 51: loss improved from 104.54169 to 103.39175, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 103.3917\n",
      "Epoch 52/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 102.8935\n",
      "Epoch 52: loss improved from 103.39175 to 102.89352, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 102.8935\n",
      "Epoch 53/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 102.1143\n",
      "Epoch 53: loss improved from 102.89352 to 102.11427, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 102.1143\n",
      "Epoch 54/300\n",
      "492/493 [============================>.] - ETA: 0s - loss: 101.7971\n",
      "Epoch 54: loss improved from 102.11427 to 101.79845, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 101.7984\n",
      "Epoch 55/300\n",
      "492/493 [============================>.] - ETA: 0s - loss: 99.3751\n",
      "Epoch 55: loss improved from 101.79845 to 99.37550, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 99.3755\n",
      "Epoch 56/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 99.8957 \n",
      "Epoch 56: loss did not improve from 99.37550\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 99.8594\n",
      "Epoch 57/300\n",
      "492/493 [============================>.] - ETA: 0s - loss: 99.0082\n",
      "Epoch 57: loss improved from 99.37550 to 98.95900, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 98.9590\n",
      "Epoch 58/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 98.5723\n",
      "Epoch 58: loss improved from 98.95900 to 98.57227, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 7s 13ms/step - loss: 98.5723\n",
      "Epoch 59/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 97.3364\n",
      "Epoch 59: loss improved from 98.57227 to 97.28973, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 97.2897\n",
      "Epoch 60/300\n",
      "489/493 [============================>.] - ETA: 0s - loss: 96.0242\n",
      "Epoch 60: loss improved from 97.28973 to 95.93486, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 95.9349\n",
      "Epoch 61/300\n",
      "489/493 [============================>.] - ETA: 0s - loss: 96.6929\n",
      "Epoch 61: loss did not improve from 95.93486\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 96.7550\n",
      "Epoch 62/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 95.5347\n",
      "Epoch 62: loss improved from 95.93486 to 95.59652, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 95.5965\n",
      "Epoch 63/300\n",
      "489/493 [============================>.] - ETA: 0s - loss: 96.1666\n",
      "Epoch 63: loss did not improve from 95.59652\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 95.9876\n",
      "Epoch 64/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 95.0033\n",
      "Epoch 64: loss improved from 95.59652 to 95.00332, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 95.0033\n",
      "Epoch 65/300\n",
      "489/493 [============================>.] - ETA: 0s - loss: 93.8346\n",
      "Epoch 65: loss improved from 95.00332 to 93.86986, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 93.8699\n",
      "Epoch 66/300\n",
      "492/493 [============================>.] - ETA: 0s - loss: 95.0124\n",
      "Epoch 66: loss did not improve from 93.86986\n",
      "493/493 [==============================] - 7s 13ms/step - loss: 94.9862\n",
      "Epoch 67/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 92.9036\n",
      "Epoch 67: loss improved from 93.86986 to 92.90363, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 7s 14ms/step - loss: 92.9036\n",
      "Epoch 68/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 93.7686\n",
      "Epoch 68: loss did not improve from 92.90363\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 93.6520\n",
      "Epoch 69/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 92.5851\n",
      "Epoch 69: loss improved from 92.90363 to 92.51823, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 7s 13ms/step - loss: 92.5182\n",
      "Epoch 70/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 92.2625\n",
      "Epoch 70: loss improved from 92.51823 to 92.29608, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 92.2961\n",
      "Epoch 71/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 91.2667\n",
      "Epoch 71: loss improved from 92.29608 to 91.26671, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 7s 14ms/step - loss: 91.2667\n",
      "Epoch 72/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 91.5022\n",
      "Epoch 72: loss did not improve from 91.26671\n",
      "493/493 [==============================] - 7s 14ms/step - loss: 91.5022\n",
      "Epoch 73/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 90.7982\n",
      "Epoch 73: loss improved from 91.26671 to 90.93089, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 7s 15ms/step - loss: 90.9309\n",
      "Epoch 74/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 90.8495\n",
      "Epoch 74: loss improved from 90.93089 to 90.84948, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 90.8495\n",
      "Epoch 75/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 90.6242\n",
      "Epoch 75: loss improved from 90.84948 to 90.62421, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 7s 14ms/step - loss: 90.6242\n",
      "Epoch 76/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 88.8568\n",
      "Epoch 76: loss improved from 90.62421 to 88.87787, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 7s 14ms/step - loss: 88.8779\n",
      "Epoch 77/300\n",
      "492/493 [============================>.] - ETA: 0s - loss: 89.8860\n",
      "Epoch 77: loss did not improve from 88.87787\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 89.8783\n",
      "Epoch 78/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 89.4709\n",
      "Epoch 78: loss did not improve from 88.87787\n",
      "493/493 [==============================] - 7s 14ms/step - loss: 89.4751\n",
      "Epoch 79/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 88.7449\n",
      "Epoch 79: loss improved from 88.87787 to 88.65703, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 7s 14ms/step - loss: 88.6570\n",
      "Epoch 80/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 88.7516\n",
      "Epoch 80: loss did not improve from 88.65703\n",
      "493/493 [==============================] - 7s 14ms/step - loss: 88.9312\n",
      "Epoch 81/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 89.2106\n",
      "Epoch 81: loss did not improve from 88.65703\n",
      "493/493 [==============================] - 7s 13ms/step - loss: 89.2491\n",
      "Epoch 82/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 89.0064\n",
      "Epoch 82: loss did not improve from 88.65703\n",
      "493/493 [==============================] - 7s 14ms/step - loss: 89.0064\n",
      "Epoch 83/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 87.8469\n",
      "Epoch 83: loss improved from 88.65703 to 87.84686, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 87.8469\n",
      "Epoch 84/300\n",
      "492/493 [============================>.] - ETA: 0s - loss: 88.2823\n",
      "Epoch 84: loss did not improve from 87.84686\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 88.2598\n",
      "Epoch 85/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 87.7031\n",
      "Epoch 85: loss improved from 87.84686 to 87.61407, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 87.6141\n",
      "Epoch 86/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 86.2133\n",
      "Epoch 86: loss improved from 87.61407 to 86.21328, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 86.2133\n",
      "Epoch 87/300\n",
      "492/493 [============================>.] - ETA: 0s - loss: 88.0831\n",
      "Epoch 87: loss did not improve from 86.21328\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 88.0556\n",
      "Epoch 88/300\n",
      "489/493 [============================>.] - ETA: 0s - loss: 87.5878\n",
      "Epoch 88: loss did not improve from 86.21328\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 87.5071\n",
      "Epoch 89/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 86.5622\n",
      "Epoch 89: loss did not improve from 86.21328\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 86.5622\n",
      "Epoch 90/300\n",
      "489/493 [============================>.] - ETA: 0s - loss: 87.6682\n",
      "Epoch 90: loss did not improve from 86.21328\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 87.6697\n",
      "Epoch 91/300\n",
      "489/493 [============================>.] - ETA: 0s - loss: 85.7679\n",
      "Epoch 91: loss improved from 86.21328 to 85.78584, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 85.7858\n",
      "Epoch 92/300\n",
      "492/493 [============================>.] - ETA: 0s - loss: 85.5905\n",
      "Epoch 92: loss improved from 85.78584 to 85.59861, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 7s 14ms/step - loss: 85.5986\n",
      "Epoch 93/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 84.9829\n",
      "Epoch 93: loss improved from 85.59861 to 84.98293, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 84.9829\n",
      "Epoch 94/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 86.6724\n",
      "Epoch 94: loss did not improve from 84.98293\n",
      "493/493 [==============================] - 7s 14ms/step - loss: 86.6724\n",
      "Epoch 95/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 86.1532\n",
      "Epoch 95: loss did not improve from 84.98293\n",
      "493/493 [==============================] - 7s 14ms/step - loss: 86.1532\n",
      "Epoch 96/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 83.8515\n",
      "Epoch 96: loss improved from 84.98293 to 83.86162, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 7s 13ms/step - loss: 83.8616\n",
      "Epoch 97/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 85.2602\n",
      "Epoch 97: loss did not improve from 83.86162\n",
      "493/493 [==============================] - 7s 14ms/step - loss: 85.3854\n",
      "Epoch 98/300\n",
      "492/493 [============================>.] - ETA: 0s - loss: 84.1151\n",
      "Epoch 98: loss did not improve from 83.86162\n",
      "493/493 [==============================] - 7s 14ms/step - loss: 84.1202\n",
      "Epoch 99/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 84.9878\n",
      "Epoch 99: loss did not improve from 83.86162\n",
      "493/493 [==============================] - 7s 13ms/step - loss: 84.9878\n",
      "Epoch 100/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 83.7538\n",
      "Epoch 100: loss improved from 83.86162 to 83.85497, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 7s 14ms/step - loss: 83.8550\n",
      "Epoch 101/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 83.5455\n",
      "Epoch 101: loss improved from 83.85497 to 83.61575, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 7s 13ms/step - loss: 83.6157\n",
      "Epoch 102/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 82.6108\n",
      "Epoch 102: loss improved from 83.61575 to 82.61082, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 7s 13ms/step - loss: 82.6108\n",
      "Epoch 103/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 82.1093\n",
      "Epoch 103: loss improved from 82.61082 to 82.10931, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 82.1093\n",
      "Epoch 104/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 81.2571\n",
      "Epoch 104: loss improved from 82.10931 to 81.23162, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 81.2316\n",
      "Epoch 105/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 81.5527\n",
      "Epoch 105: loss did not improve from 81.23162\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 81.4746\n",
      "Epoch 106/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 79.5467\n",
      "Epoch 106: loss improved from 81.23162 to 79.50514, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 7s 14ms/step - loss: 79.5051\n",
      "Epoch 107/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 79.0812\n",
      "Epoch 107: loss improved from 79.50514 to 79.13627, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 79.1363\n",
      "Epoch 108/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 78.0173\n",
      "Epoch 108: loss improved from 79.13627 to 78.00706, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 78.0071\n",
      "Epoch 109/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 77.7849\n",
      "Epoch 109: loss improved from 78.00706 to 77.77644, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 77.7764\n",
      "Epoch 110/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 77.3498\n",
      "Epoch 110: loss improved from 77.77644 to 77.34979, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 77.3498\n",
      "Epoch 111/300\n",
      "492/493 [============================>.] - ETA: 0s - loss: 75.4516\n",
      "Epoch 111: loss improved from 77.34979 to 75.58101, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 75.5810\n",
      "Epoch 112/300\n",
      "492/493 [============================>.] - ETA: 0s - loss: 74.6013\n",
      "Epoch 112: loss improved from 75.58101 to 74.58569, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 74.5857\n",
      "Epoch 113/300\n",
      "489/493 [============================>.] - ETA: 0s - loss: 73.3197\n",
      "Epoch 113: loss improved from 74.58569 to 73.22778, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 73.2278\n",
      "Epoch 114/300\n",
      "492/493 [============================>.] - ETA: 0s - loss: 73.1227\n",
      "Epoch 114: loss improved from 73.22778 to 73.08926, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 73.0893\n",
      "Epoch 115/300\n",
      "492/493 [============================>.] - ETA: 0s - loss: 71.9714\n",
      "Epoch 115: loss improved from 73.08926 to 71.93353, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 71.9335\n",
      "Epoch 116/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 71.1112\n",
      "Epoch 116: loss improved from 71.93353 to 71.11118, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 7s 14ms/step - loss: 71.1112\n",
      "Epoch 117/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 69.9493\n",
      "Epoch 117: loss improved from 71.11118 to 69.91551, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 7s 13ms/step - loss: 69.9155\n",
      "Epoch 118/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 69.7206\n",
      "Epoch 118: loss improved from 69.91551 to 69.69365, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 69.6936\n",
      "Epoch 119/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 68.0616\n",
      "Epoch 119: loss improved from 69.69365 to 68.11835, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 7s 14ms/step - loss: 68.1183\n",
      "Epoch 120/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 69.0046\n",
      "Epoch 120: loss did not improve from 68.11835\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 68.9882\n",
      "Epoch 121/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 66.0855\n",
      "Epoch 121: loss improved from 68.11835 to 66.12772, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 66.1277\n",
      "Epoch 122/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 65.4173\n",
      "Epoch 122: loss improved from 66.12772 to 65.41732, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 65.4173\n",
      "Epoch 123/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 65.6968\n",
      "Epoch 123: loss did not improve from 65.41732\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 65.7169\n",
      "Epoch 124/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 64.4883\n",
      "Epoch 124: loss improved from 65.41732 to 64.48825, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 64.4883\n",
      "Epoch 125/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 63.6325\n",
      "Epoch 125: loss improved from 64.48825 to 63.63247, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 63.6325\n",
      "Epoch 126/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 61.9018\n",
      "Epoch 126: loss improved from 63.63247 to 61.88670, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 7s 14ms/step - loss: 61.8867\n",
      "Epoch 127/300\n",
      "492/493 [============================>.] - ETA: 0s - loss: 63.0792\n",
      "Epoch 127: loss did not improve from 61.88670\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 63.0450\n",
      "Epoch 128/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 61.8749\n",
      "Epoch 128: loss improved from 61.88670 to 61.87490, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 7s 13ms/step - loss: 61.8749\n",
      "Epoch 129/300\n",
      "492/493 [============================>.] - ETA: 0s - loss: 61.5959\n",
      "Epoch 129: loss improved from 61.87490 to 61.61185, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 7s 15ms/step - loss: 61.6118\n",
      "Epoch 130/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 60.7639\n",
      "Epoch 130: loss improved from 61.61185 to 60.71856, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 7s 14ms/step - loss: 60.7186\n",
      "Epoch 131/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 60.5451\n",
      "Epoch 131: loss improved from 60.71856 to 60.58630, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 7s 14ms/step - loss: 60.5863\n",
      "Epoch 132/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 59.1618\n",
      "Epoch 132: loss improved from 60.58630 to 59.14644, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 7s 14ms/step - loss: 59.1464\n",
      "Epoch 133/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 58.2754\n",
      "Epoch 133: loss improved from 59.14644 to 58.27539, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 7s 13ms/step - loss: 58.2754\n",
      "Epoch 134/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 58.4256\n",
      "Epoch 134: loss did not improve from 58.27539\n",
      "493/493 [==============================] - 7s 14ms/step - loss: 58.4347\n",
      "Epoch 135/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 56.7645\n",
      "Epoch 135: loss improved from 58.27539 to 56.77793, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 56.7779\n",
      "Epoch 136/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 57.9198\n",
      "Epoch 136: loss did not improve from 56.77793\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 57.9149\n",
      "Epoch 137/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 56.7770\n",
      "Epoch 137: loss did not improve from 56.77793\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 56.7916\n",
      "Epoch 138/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 57.6456\n",
      "Epoch 138: loss did not improve from 56.77793\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 57.6456\n",
      "Epoch 139/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 56.9696\n",
      "Epoch 139: loss did not improve from 56.77793\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 57.0016\n",
      "Epoch 140/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 56.7190\n",
      "Epoch 140: loss improved from 56.77793 to 56.71901, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 56.7190\n",
      "Epoch 141/300\n",
      "492/493 [============================>.] - ETA: 0s - loss: 56.1623\n",
      "Epoch 141: loss improved from 56.71901 to 56.15592, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 7s 15ms/step - loss: 56.1559\n",
      "Epoch 142/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 55.2687\n",
      "Epoch 142: loss improved from 56.15592 to 55.26865, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 7s 13ms/step - loss: 55.2687\n",
      "Epoch 143/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 56.1358\n",
      "Epoch 143: loss did not improve from 55.26865\n",
      "493/493 [==============================] - 7s 13ms/step - loss: 56.1689\n",
      "Epoch 144/300\n",
      "489/493 [============================>.] - ETA: 0s - loss: 54.5370\n",
      "Epoch 144: loss improved from 55.26865 to 54.43585, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 54.4358\n",
      "Epoch 145/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 54.9485\n",
      "Epoch 145: loss did not improve from 54.43585\n",
      "493/493 [==============================] - 7s 14ms/step - loss: 54.8839\n",
      "Epoch 146/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 54.0431\n",
      "Epoch 146: loss improved from 54.43585 to 53.99501, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 53.9950\n",
      "Epoch 147/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 54.1461\n",
      "Epoch 147: loss did not improve from 53.99501\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 54.0928\n",
      "Epoch 148/300\n",
      "492/493 [============================>.] - ETA: 0s - loss: 54.0217\n",
      "Epoch 148: loss did not improve from 53.99501\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 54.0050\n",
      "Epoch 149/300\n",
      "492/493 [============================>.] - ETA: 0s - loss: 53.1530\n",
      "Epoch 149: loss improved from 53.99501 to 53.19481, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 53.1948\n",
      "Epoch 150/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 53.0376\n",
      "Epoch 150: loss improved from 53.19481 to 52.96766, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 52.9677\n",
      "Epoch 151/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 53.6549\n",
      "Epoch 151: loss did not improve from 52.96766\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 53.6549\n",
      "Epoch 152/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 52.5451\n",
      "Epoch 152: loss improved from 52.96766 to 52.56842, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 52.5684\n",
      "Epoch 153/300\n",
      "492/493 [============================>.] - ETA: 0s - loss: 53.5280\n",
      "Epoch 153: loss did not improve from 52.56842\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 53.5463\n",
      "Epoch 154/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 52.9412\n",
      "Epoch 154: loss did not improve from 52.56842\n",
      "493/493 [==============================] - 7s 13ms/step - loss: 52.9804\n",
      "Epoch 155/300\n",
      "492/493 [============================>.] - ETA: 0s - loss: 50.8677\n",
      "Epoch 155: loss improved from 52.56842 to 50.89184, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 50.8918\n",
      "Epoch 156/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 51.2633\n",
      "Epoch 156: loss did not improve from 50.89184\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 51.3897\n",
      "Epoch 157/300\n",
      "489/493 [============================>.] - ETA: 0s - loss: 52.4837\n",
      "Epoch 157: loss did not improve from 50.89184\n",
      "493/493 [==============================] - 7s 14ms/step - loss: 52.4886\n",
      "Epoch 158/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 50.9383\n",
      "Epoch 158: loss did not improve from 50.89184\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 50.9383\n",
      "Epoch 159/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 51.8172\n",
      "Epoch 159: loss did not improve from 50.89184\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 51.7564\n",
      "Epoch 160/300\n",
      "492/493 [============================>.] - ETA: 0s - loss: 50.5913\n",
      "Epoch 160: loss improved from 50.89184 to 50.59821, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 50.5982\n",
      "Epoch 161/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 50.3690\n",
      "Epoch 161: loss improved from 50.59821 to 50.45058, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 50.4506\n",
      "Epoch 162/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 51.8359\n",
      "Epoch 162: loss did not improve from 50.45058\n",
      "493/493 [==============================] - 7s 13ms/step - loss: 51.7983\n",
      "Epoch 163/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 50.6929\n",
      "Epoch 163: loss did not improve from 50.45058\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 50.6639\n",
      "Epoch 164/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 51.5278\n",
      "Epoch 164: loss did not improve from 50.45058\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 51.5278\n",
      "Epoch 165/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 50.1326\n",
      "Epoch 165: loss improved from 50.45058 to 50.09266, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 7s 13ms/step - loss: 50.0927\n",
      "Epoch 166/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 49.7587\n",
      "Epoch 166: loss improved from 50.09266 to 49.75873, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 49.7587\n",
      "Epoch 167/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 48.8042\n",
      "Epoch 167: loss improved from 49.75873 to 48.80416, saving model to /Users/kkangjun/Desktop/Study/CodeStates/Project/Project4/codestates_Project4/cong_app/ai_model/latest_model.h5\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 48.8042\n",
      "Epoch 168/300\n",
      "490/493 [============================>.] - ETA: 0s - loss: 49.2971\n",
      "Epoch 168: loss did not improve from 48.80416\n",
      "493/493 [==============================] - 6s 12ms/step - loss: 49.4468\n",
      "Epoch 169/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 49.4294\n",
      "Epoch 169: loss did not improve from 48.80416\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 49.4294\n",
      "Epoch 170/300\n",
      "491/493 [============================>.] - ETA: 0s - loss: 50.2730\n",
      "Epoch 170: loss did not improve from 48.80416\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 50.3499\n",
      "Epoch 171/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 50.2856\n",
      "Epoch 171: loss did not improve from 48.80416\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 50.2856\n",
      "Epoch 172/300\n",
      "493/493 [==============================] - ETA: 0s - loss: 49.9928\n",
      "Epoch 172: loss did not improve from 48.80416\n",
      "493/493 [==============================] - 6s 13ms/step - loss: 49.9928\n",
      "Epoch 172: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29c71ab90>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor='loss', patience=5, verbose=1)\n",
    "save_best = keras.callbacks.ModelCheckpoint(filepath=model_path + '/latest_model.h5', monitor='loss', verbose=1,\n",
    "                                            save_best_only=True, save_weights_only=False)\n",
    "\n",
    "model = base_model()\n",
    "\n",
    "model.fit(x_scaled, y_train, batch_size=128, epochs=300, callbacks=[early_stop, save_best])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cp[(dataset_cp['st_code'] == 222) & (dataset_cp['time'] == 1800)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at cong_app/ai_model/latest_model.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model2 \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcong_app/ai_model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/latest_model.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m scaler_pkl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(model_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/scaler_pickle.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pklf:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/kkangjun/miniforge3/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/kkangjun/miniforge3/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> <a href='file:///Users/kkangjun/miniforge3/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     <a href='file:///Users/kkangjun/miniforge3/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     <a href='file:///Users/kkangjun/miniforge3/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/saving/save.py:206\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/kkangjun/miniforge3/lib/python3.10/site-packages/keras/saving/save.py?line=203'>204</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath_str, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/kkangjun/miniforge3/lib/python3.10/site-packages/keras/saving/save.py?line=204'>205</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(filepath_str):\n\u001b[0;32m--> <a href='file:///Users/kkangjun/miniforge3/lib/python3.10/site-packages/keras/saving/save.py?line=205'>206</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNo file or directory found at \u001b[39m\u001b[39m{\u001b[39;00mfilepath_str\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='file:///Users/kkangjun/miniforge3/lib/python3.10/site-packages/keras/saving/save.py?line=207'>208</a>\u001b[0m   \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(filepath_str):\n\u001b[1;32m    <a href='file:///Users/kkangjun/miniforge3/lib/python3.10/site-packages/keras/saving/save.py?line=208'>209</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m saved_model_load\u001b[39m.\u001b[39mload(filepath_str, \u001b[39mcompile\u001b[39m, options)\n",
      "\u001b[0;31mOSError\u001b[0m: No file or directory found at cong_app/ai_model/latest_model.h5"
     ]
    }
   ],
   "source": [
    "model2 = tf.keras.models.load_model('cong_app/ai_model' + '/latest_model.h5')\n",
    "scaler_pkl = None\n",
    "with open(model_path + '/scaler_pickle.pkl', 'rb') as pklf:\n",
    "  scaler_pkl = pickle.load(pklf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 113ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kkangjun/miniforge3/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "2023-04-10 14:01:33.339029: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[50.263256]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = np.array([[1, 2, 211, 1, 1900]])\n",
    "new_scaled = scaler_pkl.transform(new_data)\n",
    "\n",
    "model2.predict(new_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "new_data = np.array([[1, 150, 2, 1800]])\n",
    "\n",
    "pred = model2.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.71419143676758"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.71"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(float(pred), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_len = 37\n",
    "# stride = 1\n",
    "# batch_size = 37\n",
    "\n",
    "# generator = TimeseriesGenerator(x_train, y_train, length=seq_len, stride=stride, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gru_model(layers=0):\n",
    "#   inputs = Input(shape=(seq_len, x_train.shape[1]))\n",
    "#   layer = GRU(64, activation='tanh')(inputs)\n",
    "#   layer = Dropout(0.2)(layer)\n",
    "  \n",
    "#   for _ in range(layers):\n",
    "#     layer = GRU(64, activation='tanh')(inputs)\n",
    "#     layer = Dropout(0.2)(layer)\n",
    "  \n",
    "#   outputs = Dense(1, name='output')(layer)\n",
    "  \n",
    "#   model = Model(inputs=inputs, outputs=outputs)\n",
    "  \n",
    "#   model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "  \n",
    "#   return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = gru_model(6)\n",
    "\n",
    "# model.fit(generator, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_data = np.array([[1, 1, 150, 1, 2000]])\n",
    "\n",
    "# last_sequence = x_train[-(seq_len - 1):]\n",
    "# new_sequence = np.concatenate((last_sequence, new_data), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(new_data.reshape(1, 1, x_train.shape[1]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3cacf89191c40a95faf5b7c4660fb9a17a57be1913175a649a8b42f9f34af90e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
